"""
API endpoints for large document translation (500+ pages)
"""
import json
from fastapi import APIRouter, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse
from typing import Optional
import os
import tempfile
from pathlib import Path
import logging
import uuid

from src.services.queue import QueueManager, JobStatus
from src.modules.extraction.v2.streaming_extractor import StreamingPDFExtractor

logger = logging.getLogger(__name__)

router = APIRouter(tags=["large-documents"])

queue_manager = QueueManager(redis_url=os.getenv("REDIS_URL", "redis://localhost:6379"))

@router.post("/translate")
async def translate_large_document(
    file: UploadFile = File(...),
    source_lang: str = "en",
    target_lang: str = "vi",
    tier: str = "standard",
    background_tasks: BackgroundTasks = None
):
    """
    Translate large documents (PDF or TXT)
    
    Args:
        file: PDF or TXT file to translate
        source_lang: Source language code
        target_lang: Target language code
        tier: Translation tier (basic/standard/premium)
        
    Returns:
        Job ID and status
    """
    # Accept both PDF and TXT files
    if not file.filename.endswith(('.pdf', '.txt')):
        raise HTTPException(400, "Only PDF and TXT files are supported")
    
    # Save uploaded file
    temp_dir = Path(tempfile.gettempdir()) / "prismy_uploads"
    temp_dir.mkdir(exist_ok=True)
    
    temp_path = temp_dir / f"{uuid.uuid4()}_{file.filename}"
    content = await file.read()
    with open(temp_path, "wb") as f:
        f.write(content)
    
    file_size_mb = len(content) / (1024 * 1024)
    if file_size_mb > 100:
        raise HTTPException(413, f"File too large: {file_size_mb:.1f}MB (max 100MB)")
        
    try:
        # Determine file type
        file_type = "pdf" if file.filename.endswith('.pdf') else "text"
        total_pages = 1  # Default for text files
        
        if file_type == "pdf":
            extractor = StreamingPDFExtractor()
            
            import pdfplumber
            with pdfplumber.open(temp_path) as pdf:
                total_pages = len(pdf.pages)
                
            estimate = extractor.estimate_processing_time(total_pages)
        else:
            # For text files, estimate based on file size
            estimate = {
                "minutes": max(1, int(file_size_mb * 0.5)),
                "formatted": f"{max(1, int(file_size_mb * 0.5))} minutes"
            }
        
        # Create job using QueueManager which will send to Celery
        job = await queue_manager.create_job(
            file_path=str(temp_path),
            source_lang=source_lang,
            target_lang=target_lang,
            tier=tier
        )
        
        # Update job info with file details
        job_data = {
            "job_id": job.job_id,
            "status": job.status.value,
            "progress": 0,
            "total_pages": total_pages,
            "file_type": file_type,
            "source_language": source_lang,
            "target_language": target_lang,
            "tier": tier
        }
        
        # Store in Redis using sync client for compatibility
        import redis
        r = redis.from_url("redis://localhost:6379")
        r.set(f"prismy:job:{job.job_id}", json.dumps(job_data))
        
        return JSONResponse({
            "job_id": job.job_id,
            "status": job.status.value,
            "total_pages": total_pages,
            "file_type": file_type,
            "estimated_time": estimate if file_type == "pdf" else estimate["formatted"],
            "message": f"Job created. Processing {file.filename}..."
        })
        
    except Exception as e:
        logger.error(f"Failed to create job: {e}")
        raise HTTPException(500, f"Failed to process file: {str(e)}")
        

@router.get("/status/{job_id}")
async def get_job_status(job_id: str):
    """Get job status and progress"""
    import redis
    
    # Check in Redis first
    r = redis.from_url("redis://localhost:6379")
    job_data = r.get(f"prismy:job:{job_id}")
    
    if job_data:
        try:
            data = json.loads(job_data)
            return {
                "job_id": job_id,
                "status": data.get("status", "pending"),
                "progress": data.get("progress", 0),
                "total_pages": data.get("total_pages", 0),
                "file_type": data.get("file_type", "unknown"),
                "source_language": data.get("source_language"),
                "target_language": data.get("target_language"),
                "error": data.get("error"),
                "output_file": data.get("output_file")
            }
        except:
            pass
    
    # Fallback to queue manager
    job = await queue_manager.get_job(job_id)
    
    if not job:
        raise HTTPException(404, "Job not found")
        
    return {
        "job_id": job.job_id,
        "status": job.status.value,
        "progress": job.progress,
        "total_pages": job.total_pages,
        "processed_pages": job.processed_pages,
        "created_at": job.created_at.isoformat(),
        "updated_at": job.updated_at.isoformat(),
        "error": job.error
    }
    

@router.get("/download/{job_id}")
async def download_result(job_id: str):
    """Download translation result"""
    import redis
    
    # Use sync redis for simplicity
    r = redis.from_url("redis://localhost:6379")
    
    # Check job data
    job_data = r.get(f"prismy:job:{job_id}")
    if job_data:
        try:
            data = json.loads(job_data)
            output_file = data.get('output_file')
            output_path = data.get('output_path')
            
            # Try output_path first
            if output_path and Path(output_path).exists():
                file_ext = Path(output_path).suffix
                return FileResponse(
                    path=output_path,
                    media_type='text/plain' if file_ext == '.txt' else 'application/pdf',
                    filename=f"translated_{job_id}{file_ext}",
                    headers={
                        "Content-Disposition": f'attachment; filename="translated_{job_id}{file_ext}"'
                    }
                )
            
            # Try output_file
            if output_file:
                # Check common output directories
                for base_dir in ["/tmp", "storage/output", os.environ.get("OUTPUT_DIR", "output")]:
                    full_path = Path(base_dir) / output_file
                    if full_path.exists():
                        file_ext = full_path.suffix
                        return FileResponse(
                            path=str(full_path),
                            media_type='text/plain' if file_ext == '.txt' else 'application/pdf',
                            filename=output_file,
                            headers={
                                "Content-Disposition": f'attachment; filename="{output_file}"'
                            }
                        )
        except Exception as e:
            logger.error(f"Error processing download: {e}")
    
    # Check if job exists
    job_exists = r.exists(f"prismy:job:{job_id}") or r.hgetall(f"prismy:job:{job_id}")
    if not job_exists:
        raise HTTPException(404, "Job not found")
    
    # Job exists but no output yet
    if job_data:
        data = json.loads(job_data)
        status = data.get("status", "unknown")
        if status == "completed":
            raise HTTPException(404, "Translation completed but output file not found")
        else:
            raise HTTPException(400, f"Job not completed yet. Current status: {status}")
    
    raise HTTPException(400, "Job not ready for download")


@router.get("/queue/status")
async def get_queue_status():
    """Get queue status"""
    status = await queue_manager.get_queue_status()
    active_jobs = await queue_manager.get_active_jobs()
    
    return {
        "queues": status,
        "active_jobs": [
            {
                "job_id": job.job_id,
                "status": job.status.value,
                "progress": f"{job.progress:.1f}%",
                "pages": job.total_pages
            }
            for job in active_jobs
        ]
    }
    

@router.post("/cancel/{job_id}")
async def cancel_job(job_id: str):
    """Cancel a job"""
    job = await queue_manager.get_job(job_id)
    
    if not job:
        raise HTTPException(404, "Job not found")
        
    if job.status == JobStatus.COMPLETED:
        raise HTTPException(400, "Cannot cancel completed job")
        
    await queue_manager.fail_job(job_id, "Cancelled by user")
    
    return {"message": "Job cancelled", "job_id": job_id}


def include_large_document_routes(app):
    """Include large document routes in main app"""
    app.include_router(router)