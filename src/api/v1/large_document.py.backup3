"""
API endpoints for large document translation (500+ pages)
"""
from fastapi import APIRouter, HTTPException, UploadFile, File, BackgroundTasks
from fastapi.responses import JSONResponse, FileResponse
from typing import Optional
import os
import tempfile
from pathlib import Path
import logging
import uuid

from ...services.queue import QueueManager, JobStatus
from ...modules.extraction.v2.streaming_extractor import StreamingPDFExtractor

logger = logging.getLogger(__name__)

router = APIRouter(prefix="/api/v1/large", tags=["large-documents"])

queue_manager = QueueManager(redis_url=os.getenv("REDIS_URL", "redis://localhost:6379"))

@router.post("/translate")
async def translate_large_document(
    file: UploadFile = File(...),
    source_lang: str = "vi",
    target_lang: str = "en",
    tier: str = "standard",
    background_tasks: BackgroundTasks = None
):
    """
    Translate large PDF documents (500+ pages)
    
    Args:
        file: PDF file to translate
        source_lang: Source language code
        target_lang: Target language code
        tier: Translation tier (basic/standard/premium)
        
    Returns:
        Job ID and status
    """
    if not file.filename.endswith('.pdf'):
        raise HTTPException(400, "Only PDF files are supported")
    
    # Save uploaded file
    temp_dir = Path(tempfile.gettempdir()) / "prismy_uploads"
    temp_dir.mkdir(exist_ok=True)
    
    temp_path = temp_dir / f"{uuid.uuid4()}_{file.filename}"
    content = await file.read()
    with open(temp_path, "wb") as f:
        f.write(content)
    
    file_size_mb = len(content) / (1024 * 1024)
    if file_size_mb > 100:
        raise HTTPException(413, f"File too large: {file_size_mb:.1f}MB (max 100MB)")
        
    try:
        extractor = StreamingPDFExtractor()
        
        import pdfplumber
        with pdfplumber.open(temp_path) as pdf:
            total_pages = len(pdf.pages)
            
        estimate = extractor.estimate_processing_time(total_pages)
        
        job = await queue_manager.create_job(
            file_path=str(temp_path),
            source_lang=source_lang,
            target_lang=target_lang,
            tier=tier
        )
        
        return JSONResponse({
            "job_id": job.job_id,
            "status": job.status.value,
            "total_pages": total_pages,
            "estimated_time": estimate,
            "message": f"Job created. Processing {total_pages} pages..."
        })
        
    except Exception as e:
        logger.error(f"Failed to create job: {e}")
        raise HTTPException(500, f"Failed to process file: {str(e)}")
        

@router.get("/status/{job_id}")
async def get_job_status(job_id: str):
    """Get job status and progress"""
    job = await queue_manager.get_job(job_id)
    
    if not job:
        raise HTTPException(404, "Job not found")
        
    return {
        "job_id": job.job_id,
        "status": job.status.value,
        "progress": f"{job.progress:.1f}%",
        "total_pages": job.total_pages,
        "processed_pages": job.processed_pages,
        "created_at": job.created_at.isoformat(),
        "updated_at": job.updated_at.isoformat(),
        "error": job.error
    }
    

@router.get("/download/{job_id}")
async def download_result(job_id: str):
    """Download translation result"""
    job = await queue_manager.get_job(job_id)
    
    if not job:
        raise HTTPException(404, "Job not found")
        
    if job.status != JobStatus.COMPLETED:
        raise HTTPException(400, f"Job not completed. Current status: {job.status.value}")
        
    if not job.output_file or not Path(job.output_file).exists():
        raise HTTPException(404, "Output file not found")
        
    return FileResponse(
        job.output_file,
        filename=f"translated_{Path(job.file_path).stem}.pdf",
        media_type="application/pdf"
    )
    

@router.get("/queue/status")
async def get_queue_status():
    """Get queue status"""
    status = await queue_manager.get_queue_status()
    active_jobs = await queue_manager.get_active_jobs()
    
    return {
        "queues": status,
        "active_jobs": [
            {
                "job_id": job.job_id,
                "status": job.status.value,
                "progress": f"{job.progress:.1f}%",
                "pages": job.total_pages
            }
            for job in active_jobs
        ]
    }
    

@router.post("/cancel/{job_id}")
async def cancel_job(job_id: str):
    """Cancel a job"""
    job = await queue_manager.get_job(job_id)
    
    if not job:
        raise HTTPException(404, "Job not found")
        
    if job.status == JobStatus.COMPLETED:
        raise HTTPException(400, "Cannot cancel completed job")
        
    await queue_manager.fail_job(job_id, "Cancelled by user")
    
    return {"message": "Job cancelled", "job_id": job_id}


def include_large_document_routes(app):
    """Include large document routes in main app"""
    app.include_router(router)
# Import download fix
from .download_fix import create_fixed_download_endpoint
router = create_fixed_download_endpoint(router)
